{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T21:31:23.822095Z",
     "start_time": "2025-12-19T21:26:51.219126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Завантаження тексту\n",
    "path = \"Franko_-Zibrannya-tvoriv-u-p-yatdesyati-tomah-literaturno-kritichni-praci-1900-1902-tom-33-.382254.txt\"\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "# Використовуємо перші 100 000 символів для швидкого навчання\n",
    "text = text[:100_000]\n",
    "print(\"Довжина тексту:\", len(text))\n",
    "\n",
    "# Підготовка словника\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
    "print(\"Розмір словника:\", vocab_size)\n",
    "\n",
    "SEQ_LEN = 90\n",
    "STEP = 3\n",
    "\n",
    "sequences, next_chars = [], []\n",
    "for i in range(0, len(text) - SEQ_LEN, STEP):\n",
    "    sequences.append(text[i:i + SEQ_LEN])\n",
    "    next_chars.append(text[i + SEQ_LEN])\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, next_chars):\n",
    "        self.X = torch.tensor(\n",
    "            [[char_to_idx[c] for c in seq] for seq in sequences], dtype=torch.long\n",
    "        )\n",
    "        self.y = torch.tensor([char_to_idx[c] for c in next_chars], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset = TextDataset(sequences, next_chars)\n",
    "loader = DataLoader(dataset, batch_size=128, shuffle=True, pin_memory=(device == \"cuda\"))\n",
    "\n",
    "\n",
    "# Модель GRU\n",
    "class GRUGenerator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=160):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        out = self.fc(out[:, -1])\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "model = GRUGenerator(vocab_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "print(model)\n",
    "\n",
    "# Навчання\n",
    "EPOCHS = 8\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in tqdm(loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\"):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds, _ = model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS} — Loss: {total_loss / len(loader):.4f}\")\n",
    "\n",
    "\n",
    "# Топ-k + топ-p sampling\n",
    "def sample_top_k_p(preds, k=5, p=0.9, temperature=0.7):\n",
    "    preds = torch.log(preds + 1e-9) / temperature\n",
    "    preds = torch.softmax(preds, dim=0)\n",
    "\n",
    "    top_k_probs, top_k_idx = torch.topk(preds, k)\n",
    "    top_k_probs = top_k_probs / top_k_probs.sum()\n",
    "\n",
    "    sorted_probs, sorted_idx = torch.sort(top_k_probs, descending=True)\n",
    "    cumulative_probs = torch.cumsum(sorted_probs, dim=0)\n",
    "    cutoff = (cumulative_probs > p).nonzero(as_tuple=False)\n",
    "    if len(cutoff) > 0:\n",
    "        cutoff_idx = cutoff[0].item() + 1\n",
    "        sorted_probs = sorted_probs[:cutoff_idx]\n",
    "        sorted_idx = sorted_idx[:cutoff_idx]\n",
    "        sorted_probs = sorted_probs / sorted_probs.sum()\n",
    "\n",
    "    idx = torch.multinomial(sorted_probs, 1).item()\n",
    "    return top_k_idx[sorted_idx[idx]].item()\n",
    "\n",
    "\n",
    "# Генерація тексту\n",
    "def generate_text(seed, length=500, temperature=0.7, k=5, p=0.9):\n",
    "    model.eval()\n",
    "    generated = seed\n",
    "    seq = seed[-SEQ_LEN:].lower()\n",
    "    hidden = None\n",
    "    for _ in range(length):\n",
    "        x = torch.tensor([[char_to_idx.get(c, 0) for c in seq]], dtype=torch.long).to(device)\n",
    "        with torch.no_grad():\n",
    "            preds, hidden = model(x, hidden)\n",
    "        next_idx = sample_top_k_p(torch.softmax(preds[0], dim=0), k=k, p=p, temperature=temperature)\n",
    "        next_char = idx_to_char[next_idx]\n",
    "        generated += next_char\n",
    "        seq = seq[1:] + next_char\n",
    "    return generated\n",
    "\n",
    "\n",
    "seed = (\"література українська новела і поетичний стиль з глибокими образами \"\n",
    "        \"та старовинними словами Франка \")\n",
    "\n",
    "print(generate_text(seed, temperature=0.7, k=5, p=0.9))"
   ],
   "id": "7a0178445241113d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Довжина тексту: 100000\n",
      "Розмір словника: 102\n",
      "GRUGenerator(\n",
      "  (embed): Embedding(102, 64)\n",
      "  (gru): GRU(64, 160, batch_first=True)\n",
      "  (fc): Linear(in_features=160, out_features=102, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 261/261 [00:26<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8 — Loss: 2.7638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/8: 100%|██████████| 261/261 [00:28<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/8 — Loss: 2.3148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/8: 100%|██████████| 261/261 [00:27<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/8 — Loss: 2.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/8: 100%|██████████| 261/261 [00:38<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/8 — Loss: 1.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/8: 100%|██████████| 261/261 [00:45<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/8 — Loss: 1.8735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/8: 100%|██████████| 261/261 [00:41<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/8 — Loss: 1.7738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/8: 100%|██████████| 261/261 [00:31<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/8 — Loss: 1.6828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/8: 100%|██████████| 261/261 [00:26<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/8 — Loss: 1.6018\n",
      "література українська новела і поетичний стиль з глибокими образами та старовинними словами Франка посьманних автор по станні з неї, значенним до не попує в на сам з найського і наукова того, що бутовних і вірнув і з посного на польських україні (стор. 25). по полоського те, відбував з польські в насі на відповідним до такої і наші на напів і замановим насі на відповідання притики велість до не значній матеріальніших інтерестру з наші такі повідана станні польська тільки поворобів і він вистава старальних присвітськах осніальних і попівського і не мого літературних про насільних українській р\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
